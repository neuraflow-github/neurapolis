{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 14:39:39,940 - INFO - Successfully connected to Neo4j database\n",
      "2024-09-02 14:39:40,081 - INFO - file_chunks index already exists\n",
      "2024-09-02 14:39:40,280 - INFO - All chunks have been processed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set PYTHONPATH at the start of the script\n",
    "sys.path.insert(0, \"/Users/pascal/ris/\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = AzureOpenAIEmbeddings()\n",
    "\n",
    "# Initialize Neo4j Aura connection\n",
    "uri = os.getenv(\"DB_URI\")\n",
    "username = os.getenv(\"DB_USERNAME\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "# Ensure the URI uses the 'neo4j+s' scheme for Neo4j Aura\n",
    "if uri and not uri.startswith('neo4j+s://'):\n",
    "    uri = f\"neo4j+s://{uri.split('://')[-1]}\"\n",
    "\n",
    "# Create the driver with Neo4j Aura settings\n",
    "driver = GraphDatabase.driver(\n",
    "    uri,\n",
    "    auth=(username, password),\n",
    "    max_connection_lifetime=30 * 60,  # 30 minutes\n",
    "    max_connection_pool_size=50,\n",
    "    connection_acquisition_timeout=2 * 60  # 2 minutes\n",
    ")\n",
    "\n",
    "# Verify the connection\n",
    "try:\n",
    "    with driver.session() as session:\n",
    "        session.run(\"RETURN 1\")\n",
    "    logging.info(\"Successfully connected to Neo4j database\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error connecting to Neo4j: {str(e)}\")\n",
    "    driver.close()\n",
    "    raise\n",
    "\n",
    "def get_file_chunks(limit=25, offset=0):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"MATCH (c:FileChunk) WHERE c.embedding IS NULL \"\n",
    "            \"RETURN c.id AS id, c.text AS text \"\n",
    "            \"SKIP $offset LIMIT $limit\",\n",
    "            offset=offset, limit=limit\n",
    "        )\n",
    "        return [(record[\"id\"], record[\"text\"]) for record in result]\n",
    "\n",
    "def update_file_chunk_with_embedding(tx, chunk_id, embedding):\n",
    "    tx.run(\n",
    "        \"MATCH (c:FileChunk {id: $id}) SET c.embedding = $embedding\",\n",
    "        id=chunk_id,\n",
    "        embedding=embedding\n",
    "    )\n",
    "\n",
    "def process_file_chunks():\n",
    "    offset = 0\n",
    "    max_retries = 3\n",
    "    while True:\n",
    "        file_chunks = get_file_chunks(limit=25, offset=offset)\n",
    "        if not file_chunks:\n",
    "            break\n",
    "        \n",
    "        with driver.session() as session:\n",
    "            for chunk_id, chunk_text in tqdm(file_chunks, desc=f\"Processing chunks {offset+1}-{offset+len(file_chunks)}\", unit=\"chunk\"):\n",
    "                for attempt in range(max_retries):\n",
    "                    try:\n",
    "                        embedding = embeddings.embed_query(chunk_text)\n",
    "                        session.execute_write(update_file_chunk_with_embedding, chunk_id, embedding)\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        if attempt < max_retries - 1:\n",
    "                            logging.warning(f\"Error processing chunk {chunk_id}. Retrying... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                            time.sleep(2 ** attempt)  # Exponential backoff\n",
    "                        else:\n",
    "                            logging.error(f\"Failed to process chunk {chunk_id} after {max_retries} attempts. Error: {str(e)}\")\n",
    "        \n",
    "        offset += 25\n",
    "\n",
    "def create_vector_index():\n",
    "    with driver.session() as session:\n",
    "        try:\n",
    "            # Check if the index already exists\n",
    "            result = session.run(\"SHOW INDEXES WHERE type = 'VECTOR' AND name = 'file_chunks'\")\n",
    "            if not list(result):\n",
    "                session.run(\n",
    "                    \"CALL db.index.vector.createNodeIndex('file_chunks', 'FileChunk', 'embedding', 1536, 'cosine')\"\n",
    "                )\n",
    "                logging.info(\"Created file_chunks index successfully\")\n",
    "            else:\n",
    "                logging.info(\"file_chunks index already exists\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating or checking file_chunks index: {str(e)}\")\n",
    "\n",
    "def verify_all_chunks_processed():\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (c:FileChunk) WHERE c.embedding IS NULL RETURN COUNT(c) as count\")\n",
    "        unprocessed_count = result.single()[\"count\"]\n",
    "        if unprocessed_count > 0:\n",
    "            logging.warning(f\"There are still {unprocessed_count} unprocessed chunks.\")\n",
    "        else:\n",
    "            logging.info(\"All chunks have been processed successfully.\")\n",
    "\n",
    "# Main execution\n",
    "create_vector_index()\n",
    "process_file_chunks()\n",
    "verify_all_chunks_processed()\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
